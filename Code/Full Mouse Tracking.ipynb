{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using OpenCv for Gesture Recognition and similar utilities\n",
    "import cv2\n",
    "\n",
    "# np as alias using it for numpy array operatiions\n",
    "import numpy as np\n",
    "\n",
    "# Using pynput library and using it's mouse functionality for binding\n",
    "from pynput.mouse import Button, Controller\n",
    "\n",
    "# For control of display and getting the screen resolution\n",
    "import wx\n",
    "\n",
    "# Using mouse package utility and getting the control as variable mouse\n",
    "mouse=Controller()\n",
    "\n",
    "# Setting up the wx environment for getting display\n",
    "app=wx.App(False)\n",
    "\n",
    "# Storing tuple of screen resolution in sx and sy co-ordinate variables\n",
    "(sx,sy)=wx.GetDisplaySize()\n",
    "\n",
    "# Setting manual webcam screen display window size\n",
    "(camx,camy)=(320,240)\n",
    "\n",
    "# For color segmentation using a range of green colors to identify the gesture\n",
    "lowerBound=np.array([33,80,40])\n",
    "upperBound=np.array([102,255,255])\n",
    "\n",
    "# Capturing the video and storing to cam\n",
    "cam= cv2.VideoCapture(0)\n",
    "\n",
    "# Utilities for applying smoothening filters\n",
    "kernelOpen=np.ones((5,5))\n",
    "kernelClose=np.ones((20,20))\n",
    "\n",
    "# Tracking mouse locations for smooth movements in numpy arrays\n",
    "mLocOld = np.array([0,0])\n",
    "mouseLoc = np.array([0,0])\n",
    "\n",
    "# Flag to know the switching between the state gestures.\n",
    "pinchFlag=0\n",
    "\n",
    "#Initialising window size of combined 2 gestures\n",
    "openx, openy, openw, openh =(0,0,0,0)\n",
    "\n",
    "#Damping factor for taking average  of mouse locations\n",
    "DampingFactor = 2\n",
    "\n",
    "#Loop to get the number of frames from the video and do operations on them\n",
    "while True:\n",
    "    # Capturing the video frame\n",
    "    ret, img=cam.read()\n",
    "    \n",
    "    #Resizing it to desired size\n",
    "    img=cv2.resize(img,(camx,camy))\n",
    "\n",
    "    #convert BGR to HSV\n",
    "    imgHSV= cv2.cvtColor(img,cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    # create the Mask\n",
    "    mask=cv2.inRange(imgHSV,lowerBound,upperBound)\n",
    "    \n",
    "    #Applying morphological operations on binary\n",
    "    maskOpen=cv2.morphologyEx(mask,cv2.MORPH_OPEN,kernelOpen)\n",
    "    maskClose=cv2.morphologyEx(maskOpen,cv2.MORPH_CLOSE,kernelClose)\n",
    "    \n",
    "    #Selecting the closed mask for masking green color\n",
    "    maskFinal=maskClose\n",
    "    \n",
    "    # Calculating total number of contours\n",
    "    conts,h=cv2.findContours(maskFinal.copy(),cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "    # Working logic based on number of gestures recognised\n",
    "    if(len(conts)==2):\n",
    "        #Checking for gesture state for switching the logic\n",
    "        if(pinchFlag==1):\n",
    "            pinchFlag=0\n",
    "            # If state is default removing the left click\n",
    "            mouse.release(Button.left)\n",
    "        \n",
    "        # Storing the states of co-ordinates\n",
    "        x1,y1,w1,h1=cv2.boundingRect(conts[0])\n",
    "        x2,y2,w2,h2=cv2.boundingRect(conts[1])\n",
    "        \n",
    "        # Capturing them in rectangles of blue color\n",
    "        cv2.rectangle(img,(x1,y1),(x1+w1,y1+h1),(255,0,0),2)\n",
    "        cv2.rectangle(img,(x2,y2),(x2+w2,y2+h2),(255,0,0),2)\n",
    "        \n",
    "        # Taking out the average of the cordinates to find the centre of rectangle\n",
    "        cx1=x1+w1/2\n",
    "        cy1=y1+h1/2\n",
    "        cx2=x2+w2/2\n",
    "        cy2=y2+h2/2\n",
    "        \n",
    "        # Taking out the average of the cordinates to find the centre of the line joining the centres.\n",
    "        cx=(cx1+cx2)/2\n",
    "        cy=(cy1+cy2)/2\n",
    "        \n",
    "        # Drawing the line of blue color between the centres of rectangle\n",
    "        cv2.line(img, (cx1,cy1),(cx2,cy2),(255,0,0),2)\n",
    "        \n",
    "        #Drawing a bullet circle on the centre of the line for mouse binding\n",
    "        cv2.circle(img, (cx,cy),2,(0,0,255),2)\n",
    "        \n",
    "        # Changing of mouse cursor's new location based on the previous cordinated of cursor\n",
    "        mouseLoc = mLocOld + ((cx,cy)-mLocOld)/DampingFactor\n",
    "        \n",
    "        # Alloting new position to the mouse cursor on the weighted average of cordinates\n",
    "        mouse.position=(sx-(mouseLoc[0]*sx/camx),mouseLoc[1]*sy/camy)\n",
    "        \n",
    "        # Pasisng the logic if condition does not satisfy\n",
    "        while mouse.position!=(sx-(mouseLoc[0]*sx/camx), mouseLoc[1]*sy/camy):\n",
    "            pass\n",
    "        \n",
    "        #Storing the old mouse location for next usage.\n",
    "        mLocOld = mouseLoc\n",
    "        \n",
    "        # Calculating the bigger rectangle of combined gestures for area estimation\n",
    "        openx, openy, openw, openh = cv2.boundingRect(np.array([[[x1,y1],[x1+w1,y1+h1],[x2,y2],[x2+w2,y2+h2]]]))\n",
    "        \n",
    "        # Uncomment below to check the bigger rectangle of combined gestures\n",
    "        #cv2.rectangle(img,(openx,openy),(openx+openw,openy+openh),(255,0,0),2)\n",
    "        \n",
    "        # Clicking operations if the objects merges to one\n",
    "    elif(len(conts)==1):\n",
    "        # Bounding rectangle on the single object created\n",
    "        x,y,w,h=cv2.boundingRect(conts[0])\n",
    "        \n",
    "        #Checking the flag condition\n",
    "        if(pinchFlag==0):\n",
    "            # Checking if one object goes out of screen what should be difference in the ratios so that logic applies\n",
    "            if(abs((w*h - openw*openh)*100/(w*h)) < 30):\n",
    "                pinchFlag=1\n",
    "                \n",
    "                #Click the left button\n",
    "                mouse.press(Button.left)\n",
    "                openx, openy, openw, openh =(0,0,0,0)\n",
    "        else:\n",
    "            #Otherwise if closing to opening the gesture then don't press\n",
    "            cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "            cx=x+w/2\n",
    "            cy=y+h/2\n",
    "            cv2.circle(img,(cx,cy),(w+h)/4,(0,0,255),2)\n",
    "            \n",
    "            # Store the mouse location\n",
    "            mouseLoc = mLocOld + ((cx,cy)-mLocOld)/DampingFactor\n",
    "            mouse.position=(sx-(mouseLoc[0]*sx/camx), mouseLoc[1]*sy/camy)\n",
    "            \n",
    "            # Checking again\n",
    "            while mouse.position!=(sx-(mouseLoc[0]*sx/camx), mouseLoc[1]*sy/camy):\n",
    "                pass\n",
    "            mLocOld = mouseLoc\n",
    "            \n",
    "    # Showing on webcam\n",
    "    cv2.imshow(\"cam\",img)\n",
    "    \n",
    "    # Waiting for frames on the basis of ticks.\n",
    "    cv2.waitKey(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
